{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keirVQGAN/aida/blob/main/Aida_Common.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###// **AiDa** Setup `aida.py`"
      ],
      "metadata": {
        "id": "irQ0Hzw056yV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ry8OWqI3VV2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  <------------ //Aida Common Setup\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from distutils.dir_util import copy_tree\n",
        "import json\n",
        "from IPython import display\n",
        "from IPython.display import Image\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "def _gif(lists,out,delay,scale):\n",
        "  gifOut = f'/content/out/gifs/{out}.gif'\n",
        "  !convert -delay $delay -resize $scale -loop 0 $lists $gifOut\n",
        "\n",
        "def gifShow(Path):\n",
        "  with open(Path,'rb') as f:\n",
        "      a = display.Image(data=f.read(), format='png')\n",
        "      return a\n",
        "\n",
        "#VARIABLES\n",
        "localPath = '/content'\n",
        "tmpPath = f'{localPath}/tmp'\n",
        "#GITHUB - Aida.git\n",
        "gitted = os.path.isdir(tmpPath)\n",
        "if gitted==0:\n",
        "  os.makedirs(tmpPath, exist_ok=\"True\")\n",
        "  !git clone https://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@github.com/keirVQGAN/aida /content/tmp\n",
        "copied = os.path.isfile(f'{localPath}/aida.py')\n",
        "if copied==0:\n",
        "  copy_tree(tmpPath, localPath)\n",
        "#INSTALL - Requirements\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "import aida\n",
        "#CLONE - IN\n",
        "clonned = os.path.isdir('/content/in')\n",
        "if clonned==0:\n",
        "  aida.clone()\n",
        "#Import [DEFAULT] Paths\n",
        "config_file = '/content/config.ini'\n",
        "import configparser\n",
        "config = configparser.ConfigParser()\n",
        "config.read(config_file)\n",
        "_project_ls = json.loads(config.get(\"DEFAULT\",\"PROJECT\"))\n",
        "_exp_ls = json.loads(config.get(\"DEFAULT\",\"EXPERIMENT\"))\n",
        "_drivePath_ls = json.loads(config.get(\"DEFAULT\",\"DRIVE_PATH\"))\n",
        "_localPath_ls = json.loads(config.get(\"DEFAULT\",\"LOCAL_PATH\"))\n",
        "_modelsPath_ls = json.loads(config.get(\"DEFAULT\",\"MODELS_PATH\"))\n",
        "_modelsPathDrive_ls = json.loads(config.get(\"DEFAULT\",\"MODELS_PATH_DRIVE\"))\n",
        "_inPath_ls = json.loads(config.get(\"DEFAULT\",\"IN_PATH\"))\n",
        "_inPathDrive_ls = json.loads(config.get(\"DEFAULT\",\"IN_PATH_DRIVE\"))\n",
        "_outPath_ls = json.loads(config.get(\"DEFAULT\",\"OUT_PATH\"))\n",
        "_outPathDrive_ls = json.loads(config.get(\"DEFAULT\",\"OUT_PATH_DRIVE\"))\n",
        "_contactPath_ls = json.loads(config.get(\"DEFAULT\",\"CONTACT_PATH\"))\n",
        "_archivePath_ls = json.loads(config.get(\"DEFAULT\",\"ARCHIVE_PATH\"))\n",
        "_iniPath_ls = json.loads(config.get(\"IMAGES\",\"INI_PATH\"))\n",
        "_stylesPath_ls = json.loads(config.get(\"IMAGES\",\"STYLES_PATH\"))\n",
        "_maskPath_ls = json.loads(config.get(\"IMAGES\",\"MASKS_PATH\"))\n",
        "\n",
        "NEURALed_ls = json.loads(config.get(\"DEFAULT\", \"NEURAL\"))\n",
        "TRANed_ls = json.loads(config.get(\"DEFAULT\", \"TRANS\"))\n",
        "FILMed_ls = json.loads(config.get(\"DEFAULT\", \"FILM\"))\n",
        "SUPERed_ls = json.loads(config.get(\"DEFAULT\", \"SUPER\"))\n",
        "TXT2IMGed_ls = json.loads(config.get(\"DEFAULT\", \"TXT2IMG\"))\n",
        "\n",
        "_project = aida.ls2str(_project_ls)\n",
        "_exp = aida.ls2str(_exp_ls)\n",
        "_drivePath = aida.ls2str(_drivePath_ls)\n",
        "_localPath = aida.ls2str(_localPath_ls)\n",
        "_modelsPath = aida.ls2str(_modelsPath_ls)\n",
        "_modelsPathDrive = aida.ls2str(_modelsPathDrive_ls)\n",
        "_inPath = aida.ls2str(_inPath_ls)\n",
        "_inPathDrive = aida.ls2str(_inPathDrive_ls)\n",
        "_outPath = aida.ls2str(_outPath_ls)\n",
        "_outPathDrive = aida.ls2str(_outPathDrive_ls)\n",
        "_contactPath = aida.ls2str(_contactPath_ls)\n",
        "_archivePath = aida.ls2str(_archivePath_ls)\n",
        "_iniPath = aida.ls2str(_iniPath_ls)\n",
        "_stylesPath = aida.ls2str(_stylesPath_ls)\n",
        "_maskPath = aida.ls2str(_maskPath_ls)\n",
        "\n",
        "NEURALed = aida.ls2str(NEURALed_ls)\n",
        "TRANed = aida.ls2str(TRANed_ls)\n",
        "FILMed = aida.ls2str(FILMed_ls)\n",
        "SUPERed = aida.ls2str(SUPERed_ls)\n",
        "TXT2IMGed = aida.ls2str(TXT2IMGed_ls)\n",
        "\n",
        "#Get images lists\n",
        "_ini_ls = aida.ls(_iniPath)\n",
        "_ini_ls_str = aida.ls2str(_ini_ls)\n",
        "_style_ls = aida.ls(_stylesPath)\n",
        "_style_ls_str = aida.ls2str(_style_ls)\n",
        "_mask_ls = aida.ls(_maskPath)\n",
        "_mask_ls_str = aida.ls2str(_mask_ls)\n",
        "\n",
        "!apt install imagemagick &> /dev/null\n",
        "aida.mk(f'{_outPath}/gifs')\n",
        "\n",
        "style_gifed = os.path.isdir('/content/out/gifs/styles.gif')\n",
        "if style_gifed ==0:\n",
        "  aida.mk('/content/out/gifs/styles/')\n",
        "  _gif(_style_ls_str,\"/styles/styles\",\"100\",\"17%\")\n",
        "\n",
        "#Clean Up\n",
        "tmpd = os.path.isdir('/content/tmp')\n",
        "sampled = os.path.isdir('/content/sample_data')\n",
        "if tmpd==1:\n",
        "  aida.rm('/content/tmp')\n",
        "if sampled==1:\n",
        "  aida.rm('/content/sample_data') \n",
        "\n",
        "#Console\n",
        "installed = ['AiDa', 'requirements']\n",
        "cloned = ['github/keirVQGAN/aida','/mnt/drive/aida/in']\n",
        "#CONFIG [DEFAULT] LISTS\n",
        "paramConfigDefault = [\"PROJECT\",\"DRIVE_PATH\",\"LOCAL_PATH\",\"MODELS_PATH\",\"MODELS_PATH_DRIVE\",\"IN_PATH\",\"IN_PATH_DRIVE\",\"OUT_PATH\",\"OUT_PATH_DRIVE\",\"CONTACT_PATH\",\"ARCHIVE_PATH\"]\n",
        "valueConfigDefault = [_project,_drivePath,_localPath,_modelsPath,_modelsPathDrive,_inPath,_inPathDrive,_outPath,_outPathDrive,_contactPath,_archivePath]\n",
        "paramConfigImages = [\"INI_PATH\",\"STYLES_PATH\",\"MASKS_PATH\"]\n",
        "valueConfigImages = [_iniPath,_stylesPath,_maskPath]\n",
        "paramConfigRenderers = \"NEURAL\",\"TRANS\",\"FILM\",\"SUPER\",\"TXT2IMG\"\n",
        "valueConfigRenderers = NEURALed,TRANed,FILMed,SUPERed,TXT2IMGed\n",
        "print()\n",
        "aida.txtH('AiDa v0.1 // Setup')\n",
        "for q in installed:\n",
        "  aida.txtC('Installed',q)\n",
        "for w in cloned:\n",
        "  aida.txtY('Cloned', w)\n",
        "aida.txtM('Imported', '[DEFAULT] config')\n",
        "print()\n",
        "aida.txtH('Renderers')\n",
        "for y,x in zip(paramConfigRenderers,valueConfigRenderers):\n",
        "  x = config.get(\"NEURAL\", y)\n",
        "  aida.txt(y,x)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FKeJ-GqX4wEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###// **AiDa**  Install `renderers`"
      ],
      "metadata": {
        "id": "Z3Ju5WWFVTeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### // Render"
      ],
      "metadata": {
        "id": "gX8ZFAn-nuIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYgCr21UEfoA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "if NEURALed=='TRUE':\n",
        "  #@markdown <----------- **AiDa** // INSTALL - NeuralStyle Transfer\n",
        "  #Import [Neural] Parameters\n",
        "  from IPython.display import Image\n",
        "  config.read(config_file)\n",
        "  _img_size_ls = json.loads(config.get(\"NEURAL\", \"IMG_SIZE\"))\n",
        "  _run_ls = json.loads(config.get(\"NEURAL\", \"RUN\"))\n",
        "  _style_weight_ls = json.loads(config.get(\"NEURAL\", \"STYLE_WEIGHT\"))\n",
        "  _min_improvement_ls = json.loads(config.get(\"NEURAL\", \"MIN_IMPROVEMENT\"))\n",
        "  _content_weight_ls = json.loads(config.get(\"NEURAL\", \"CONTENT_WEIGHT\"))\n",
        "  _content_loss_type_ls = json.loads(config.get(\"NEURAL\", \"CONTENT_LOSS_TYPE\"))\n",
        "  _pool_type_ls = json.loads(config.get(\"NEURAL\", \"POOL_TYPE\"))\n",
        "  _tv_weight_ls = json.loads(config.get(\"NEURAL\", \"TV_WEIGHT\"))\n",
        "  _model_ls = json.loads(config.get(\"NEURAL\", \"MODEL\"))\n",
        "\n",
        "  _img_size =  aida.ls2str(_img_size_ls)\n",
        "  _run =  aida.ls2str(_run_ls)\n",
        "  _style_weight =  aida.ls2str(_style_weight_ls)\n",
        "  _min_improvement =  aida.ls2str(_min_improvement_ls)\n",
        "  _content_weight =  aida.ls2str(_content_weight_ls)\n",
        "  _content_loss_type =  aida.ls2str(_content_loss_type_ls)\n",
        "  _pool_type =  aida.ls2str(_pool_type_ls)\n",
        "  _tv_weight =  aida.ls2str(_tv_weight_ls)\n",
        "  _model = aida.ls2str(_model_ls)\n",
        "\n",
        "  #Install Requirements\n",
        "  from IPython.display import Image\n",
        "  %tensorflow_version 1.x\n",
        "\n",
        "  !pip install -q 'scipy<=1.2.1' &> /dev/null\n",
        "  gittedNeu = os.path.isdir('/content/Neural-Style-Transfer')\n",
        "  if gittedNeu==0:\n",
        "    !git clone https://github.com/titu1994/Neural-Style-Transfer.git &> /dev/null\n",
        "  dir_path = \"Neural-Style-Transfer\"\n",
        "  NETWORK = 'INetwork' + '.py'\n",
        "\n",
        "  #Console\n",
        "  paramConfig = [\"RUN\",\"IMG_SIZE\",\"CONTENT_WEIGHT\",\"STYLE_WEIGHT\",\"MIN_IMPROVEMENT\",\"CONTENT_LOSS_TYPE\",\"TV_WEIGHT\",\"POOL_TYPE\",\"MODEL\"]\n",
        "  valueConfig = [_run,_img_size,_content_weight,_style_weight,_min_improvement,_content_loss_type,_tv_weight,_pool_type,_model]\n",
        "  aida.txtH('AiDa v0.1 // NeuralTransfer')\n",
        "  aida.txtC('Installed','requirements')\n",
        "  print()\n",
        "  aida.txtM(_project,f'run_{_exp}')\n",
        "  for y,x in zip(paramConfig,valueConfig):\n",
        "    x = config.get(\"NEURAL\", y)\n",
        "    aida.txt(y,x)\n",
        "  print()\n",
        "  gifShow('/content/out/gifs/styles/styles.gif')\n",
        "  Image(_ini_ls_str, width=218)\n",
        "else:\n",
        "    aida.txt(\"Neural Transfer Not Selected in\", \"conif.ini\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // INSTALL - StyleTransfer [pytorch]\n",
        "#Import [Neural] Parameters\n",
        "from IPython.display import Image\n",
        "if TRANed=='TRUE':\n",
        "  config.read(config_file)\n",
        "  TRANSproject_ls = json.loads(config.get(\"TRANS\", \"PROJECT\"))\n",
        "  TRANSexp_ls = json.loads(config.get(\"TRANS\", \"EXP\"))\n",
        "  TRANSweight_ls = json.loads(config.get(\"TRANS\", \"WEIGHT\"))\n",
        "  TRANStv_weight_ls = json.loads(config.get(\"TRANS\", \"SMOOTH\"))\n",
        "  TRANSsize_ls = json.loads(config.get(\"TRANS\", \"SIZE\"))\n",
        "  TRANSrun_ls = json.loads(config.get(\"TRANS\", \"RUN\"))\n",
        "  TRANSrun_ini_ls = json.loads(config.get(\"TRANS\", \"RUN_INI\"))\n",
        "  TRANSsave_ls = json.loads(config.get(\"TRANS\", \"SAVE\"))\n",
        "  TRANSrate_ls = json.loads(config.get(\"TRANS\", \"RATE\"))\n",
        "  TRANSdecay_ls = json.loads(config.get(\"TRANS\", \"DECAY\"))\n",
        "\n",
        "  TRANSproject = aida.ls2str(TRANSproject_ls)\n",
        "  TRANSexp = aida.ls2str(TRANSexp_ls)\n",
        "  TRANSweight = aida.ls2str(TRANSweight_ls)\n",
        "  TRANStv_weight = aida.ls2str(TRANStv_weight_ls)\n",
        "  TRANSsize = aida.ls2str(TRANSsize_ls)\n",
        "  TRANSrun = aida.ls2str(TRANSrun_ls)\n",
        "  TRANSrun_ini = aida.ls2str(TRANSrun_ini_ls)\n",
        "  TRANSsave = aida.ls2str(TRANSsave_ls)\n",
        "  TRANSrate = aida.ls2str(TRANSrate_ls)\n",
        "  TRANSdecay = aida.ls2str(TRANSdecay_ls)\n",
        "\n",
        "  #Varibale List - Trans\n",
        "  valueConfigTrans = TRANSproject,TRANSexp,TRANSweight,TRANStv_weight,TRANSsize,TRANSrun,TRANSrun_ini,TRANSsave,TRANSrate,TRANSdecay\n",
        "  paramConfigTrans = \"PROJECT\",\"EXP\",\"WEIGHT\",\"SMOOTH\",\"SIZE\",\"RUN\",\"RUN_INI\",\"SAVE\",\"RATE\",\"DECAY\"\n",
        "\n",
        "  gittedTrans = os.path.isdir('/content/style-transfer-pytorch')\n",
        "  if gittedTrans==0:\n",
        "    !git clone https://github.com/crowsonkb/style-transfer-pytorch    &> /dev/null\n",
        "    !pip install -e ./style-transfer-pytorch &> /dev/null\n",
        "\n",
        "  aida.txtC('Installed','StyleTransfer [pytorch]')\n",
        "  print()\n",
        "  aida.txtM(_project,f'run_{_exp}')\n",
        "  for y,x in zip(paramConfigTrans,valueConfigTrans):\n",
        "    x = config.get(\"TRANS\", y)\n",
        "    aida.txt(y,x)\n",
        "  print()\n",
        "  gifShow('/content/out/gifs/styles/styles.gif')\n",
        "  Image(_ini_ls_str, width=218)\n",
        "else:\n",
        "  aida.txt(\"Style Transfer Not Selected in\", \"conif.ini\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CjeywiACkOZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####// Post Render\n",
        "\n"
      ],
      "metadata": {
        "id": "tmTBt_Tindd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // INSTALL - SuperRez\n",
        "if SUPERed=='TRUE':\n",
        "  print('hello')\n",
        "else:\n",
        "  aida.txt(\"SuperRez Not Selected in\", \"conif.ini\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ei7YGj93W9rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // INSTALL - FILM Interpolator\n",
        "if FILMed=='TRUE':\n",
        "  print('hello')\n",
        "else:\n",
        "  aida.txt(\"FILM Not Selected in\", \"conif.ini\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OqisuPddXAqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###// **AiDa** Render"
      ],
      "metadata": {
        "id": "NFob7Xny6DzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // Neural Transfer - Render\n",
        "rendererName = \"NEURAL\" #[CHANGE FOR EACH RENDERER]\n",
        "aida.txtC('Rendering', f'{rendererName} Transfer...')       \n",
        "if NEURALed=='TRUE':\n",
        "  #Set Initial Image Path\n",
        "  iniName = aida.name(_ini_ls_str)\n",
        "  #Set Batch option [option as list in config.ini]\n",
        "  option_ls = _style_weight_ls\n",
        "  str(option_ls)\n",
        "  #Run loop using images in '/content/in/styles/*' with '/content/in/ini/initialImage.png'\n",
        "  for style in _style_ls:\n",
        "    styleName = aida.name(style)    \n",
        "    for option in option_ls:\n",
        "      #Set output file path and name\n",
        "      optionName = aida.name(option)\n",
        "      ##Make the output folder for the runs\n",
        "      aida.mk(f'{_outPath}/images/{rendererName}/images/{_project}/run_{_exp}/{iniName}/{optionName}/{styleName}/')\n",
        "      outImg = f'{_outPath}/images/{rendererName}/images/{_project}/run_{_exp}/{iniName}/{optionName}/{styleName}/{iniName}-x-{styleName}---{optionName}'\n",
        "      #Run the Renderer\n",
        "      !python /content/Neural-Style-Transfer/Network.py $_ini_ls_str $style $outImg --image_size $_img_size --num_iter $_run --style_weight $option --content_weight $_content_weight\n",
        "      #Sync `/content/out' '/mnt/drive/MyDrive/aida/out\n",
        "      aida.syncDir(_outPath,_outPathDrive)\n",
        "else:\n",
        "    aida.txt(f'{rendererName} Transfer Not Selected in', \"conif.ini\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ehZ2TR9o-1wn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0e5debc-e3cf-4517-b983-d648738d09c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">Rendering</span> -&gt; <span style=\"background-color: #000000\">NEURAL Transfer...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[96mRendering\u001b[0m -> \u001b[7;30mNEURAL Transfer\u001b[0m\u001b[7;30m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['10', '15', '20']\""
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n",
            "2022-04-11 15:28:35.808512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-11 15:28:35.941910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:35.942540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-11 15:28:35.944476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-11 15:28:36.105982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-11 15:28:36.123140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-11 15:28:36.132255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-11 15:28:36.297978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-11 15:28:36.307362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-11 15:28:36.602236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-11 15:28:36.602428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.603153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.603717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-11 15:28:36.612243: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2022-04-11 15:28:36.612708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555dd28fe540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-11 15:28:36.612742: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-11 15:28:36.862245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.863047: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555dd28fe700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-11 15:28:36.863085: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-04-11 15:28:36.863260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.863854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-11 15:28:36.863908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-11 15:28:36.863929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-11 15:28:36.863944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-11 15:28:36.863962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-11 15:28:36.863977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-11 15:28:36.863991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-11 15:28:36.864007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-11 15:28:36.864064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.864688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.865240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-11 15:28:36.868556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-11 15:28:36.870113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-11 15:28:36.870148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-11 15:28:36.870163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-11 15:28:36.872053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.872736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-11 15:28:36.873290: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-11 15:28:36.873328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model loaded.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Starting iteration 1 of 35\n",
            "2022-04-11 15:28:41.764893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-11 15:28:42.395922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "Current loss value: 13049288000.0  Improvement : 0.000 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_1.png\n",
            "Iteration 1 completed in 29s\n",
            "Starting iteration 2 of 35\n",
            "Current loss value: 5069734000.0  Improvement : 61.149 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_2.png\n",
            "Iteration 2 completed in 19s\n",
            "Starting iteration 3 of 35\n",
            "Current loss value: 2974397200.0  Improvement : 41.330 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_3.png\n",
            "Iteration 3 completed in 20s\n",
            "Starting iteration 4 of 35\n",
            "Current loss value: 2085630600.0  Improvement : 29.881 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_4.png\n",
            "Iteration 4 completed in 20s\n",
            "Starting iteration 5 of 35\n",
            "Current loss value: 1549393300.0  Improvement : 25.711 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_5.png\n",
            "Iteration 5 completed in 21s\n",
            "Starting iteration 6 of 35\n",
            "Current loss value: 1223485700.0  Improvement : 21.035 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_6.png\n",
            "Iteration 6 completed in 22s\n",
            "Starting iteration 7 of 35\n",
            "Current loss value: 1006226560.0  Improvement : 17.757 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_7.png\n",
            "Iteration 7 completed in 21s\n",
            "Starting iteration 8 of 35\n",
            "Current loss value: 853055600.0  Improvement : 15.222 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_8.png\n",
            "Iteration 8 completed in 21s\n",
            "Starting iteration 9 of 35\n",
            "Current loss value: 740372900.0  Improvement : 13.209 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_9.png\n",
            "Iteration 9 completed in 21s\n",
            "Starting iteration 10 of 35\n",
            "Current loss value: 650183500.0  Improvement : 12.182 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_10.png\n",
            "Iteration 10 completed in 21s\n",
            "Starting iteration 11 of 35\n",
            "Current loss value: 578843200.0  Improvement : 10.972 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_11.png\n",
            "Iteration 11 completed in 21s\n",
            "Starting iteration 12 of 35\n",
            "Current loss value: 519705730.0  Improvement : 10.216 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_12.png\n",
            "Iteration 12 completed in 21s\n",
            "Starting iteration 13 of 35\n",
            "Current loss value: 467615170.0  Improvement : 10.023 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_13.png\n",
            "Iteration 13 completed in 21s\n",
            "Starting iteration 14 of 35\n",
            "Current loss value: 425077500.0  Improvement : 9.097 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_14.png\n",
            "Iteration 14 completed in 21s\n",
            "Starting iteration 15 of 35\n",
            "Current loss value: 388832450.0  Improvement : 8.527 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_15.png\n",
            "Iteration 15 completed in 21s\n",
            "Starting iteration 16 of 35\n",
            "Current loss value: 357894850.0  Improvement : 7.957 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_16.png\n",
            "Iteration 16 completed in 21s\n",
            "Starting iteration 17 of 35\n",
            "Current loss value: 331359230.0  Improvement : 7.414 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_17.png\n",
            "Iteration 17 completed in 21s\n",
            "Starting iteration 18 of 35\n",
            "Current loss value: 308184400.0  Improvement : 6.994 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_18.png\n",
            "Iteration 18 completed in 21s\n",
            "Starting iteration 19 of 35\n",
            "Current loss value: 287590660.0  Improvement : 6.682 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_19.png\n",
            "Iteration 19 completed in 21s\n",
            "Starting iteration 20 of 35\n",
            "Current loss value: 269347740.0  Improvement : 6.343 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_20.png\n",
            "Iteration 20 completed in 21s\n",
            "Starting iteration 21 of 35\n",
            "Current loss value: 253247870.0  Improvement : 5.977 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_21.png\n",
            "Iteration 21 completed in 21s\n",
            "Starting iteration 22 of 35\n",
            "Current loss value: 238244510.0  Improvement : 5.924 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_22.png\n",
            "Iteration 22 completed in 21s\n",
            "Starting iteration 23 of 35\n",
            "Current loss value: 225131470.0  Improvement : 5.504 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_23.png\n",
            "Iteration 23 completed in 21s\n",
            "Starting iteration 24 of 35\n",
            "Current loss value: 213354580.0  Improvement : 5.231 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_24.png\n",
            "Iteration 24 completed in 21s\n",
            "Starting iteration 25 of 35\n",
            "Current loss value: 202566560.0  Improvement : 5.056 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_25.png\n",
            "Iteration 25 completed in 21s\n",
            "Starting iteration 26 of 35\n",
            "Current loss value: 192778860.0  Improvement : 4.832 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_26.png\n",
            "Iteration 26 completed in 21s\n",
            "Starting iteration 27 of 35\n",
            "Current loss value: 184077440.0  Improvement : 4.514 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_27.png\n",
            "Iteration 27 completed in 21s\n",
            "Starting iteration 28 of 35\n",
            "Current loss value: 176385260.0  Improvement : 4.179 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_28.png\n",
            "Iteration 28 completed in 21s\n",
            "Starting iteration 29 of 35\n",
            "Current loss value: 169034500.0  Improvement : 4.167 %\n",
            "Rescaling Image to (1080, 720)\n",
            "Image saved as /content/out/images/NEURAL/images/Earth/run_3/face/10/style_36/face-x-style_36---10_at_iteration_29.png\n",
            "Iteration 29 completed in 21s\n",
            "Starting iteration 30 of 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // Neural Transfer - Render\n",
        "rendererName = \"NEURAL\" #[CHANGE FOR EACH RENDERER]\n",
        "aida.txtC('Rendering', f'{rendererName} Transfer...')       \n",
        "if NEURALed=='TRUE':\n",
        "    #Set Initial Image Path\n",
        "    iniName = aida.name(_ini_ls_str)\n",
        "    #Set Batch option [option as list in config.ini]\n",
        "    option_ls = _style_weight_ls\n",
        "    str(option_ls)\n",
        "    #Run loop using images in '/content/in/styles/*' with '/content/in/ini/initialImage.png'\n",
        "    for style, option in zip(_style_ls,option_ls):\n",
        "        #Set output file path and name\n",
        "        styleName = aida.name(option)\n",
        "        optionName = aida.name(style)\n",
        "        ##Make the output folder for the runs\n",
        "        aida.mk(f'{_outPath}/{rendererName}/images/{_project}/run_{_exp}/{iniName}/{optionName}/{styleName}/')\n",
        "        outImg = f'{_outPath}/images/{rendererName}/{_project}/run_{_exp}/{iniName}/{optionName}/{styleName}/{iniName}-x-{styleName}---{optionName}'\n",
        "        #Run the Renderer\n",
        "        !python /content/Neural-Style-Transfer/Network.py $_ini_ls_str $style $outImg --image_size $_img_size --num_iter $_run --style_weight $option --content_weight $_content_weight\n",
        "        #Sync `/content/out' '/mnt/drive/MyDrive/aida/out\n",
        "        aida.syncDir(_outPath,_outPathDrive)\n",
        "else:\n",
        "    aida.txt(f'{rendererName} Transfer Not Selected in', \"conif.ini\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Aa81e2F_vOc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "rendererName = \"NEURAL\"\n",
        "#@markdown <----------- **AiDa** // Post and Archive Run\n",
        "finalIn = Path(\"/content/out/images/NEURAL\")\n",
        "finalOut = f'/content/out/final/{_project}/run_{_exp}'\n",
        "aida.mk(finalOut)\n",
        "pat = f'*{_run}*.png'\n",
        "#COPY - Final iterations '../final/project/run/'\n",
        "for final in finalIn.rglob(pat):\n",
        "  !cp $final $finalOut\n",
        "#SYNC\n",
        "aida.syncDir(_outPath,_outPathDrive)\n",
        "#CONTACT - Final Run\n",
        "_finalLs = aida.ls(finalOut)\n",
        "_finalLs_str = aida.ls2str(_finalLs)\n",
        "out = f'/content/out/contacts/{_project}/run_{_exp}/contact.jpg'\n",
        "aida.mk(f'/content/out/contacts/{_project}/run_{_exp}/')\n",
        "aida.mk(f'/content/out/gifs/{_project}/run_{_exp}/')\n",
        "#GIF - Final Renders\n",
        "gifName = f'/{_project}/run_{_exp}/final'\n",
        "!montage -geometry 216x+0 -background grey34 $_finalLs_str $out\n",
        "_gif(_finalLs_str,gifName,\"100\",\"70%\")\n",
        "#SYNC\n",
        "aida.syncDir(_outPath,_outPathDrive)\n",
        "#GIF - all run iterations\n",
        "rootdir = '/content/out/images/'\n",
        "frames_ls = []\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "    for file in files:\n",
        "        frames_ls.append(os.path.join(subdir, file))\n",
        "frames = aida.ls2str(frames_ls)\n",
        "aida.mk('/content/out/gifs/frames')\n",
        "_gif(frames,\"frames/frames\",\"30\",\"70%\")\n",
        "#SYNC\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "timeSlug = now.strftime(\"%H-%M-%S\")\n",
        "aida.zip( f'{_archivePath}/{_project}-run_{_exp}_{timeSlug}.zip','/content/out')\n",
        "aida.syncDir(_outPath,_outPathDrive)"
      ],
      "metadata": {
        "id": "J4D3VIWJEZdw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // Neural Transfer - Render\n",
        "rendererName = \"TRANS\" \n",
        "aida.txtC('Rendering', f'{rendererName} Transfer...')       \n",
        "if TRANed=='TRUE':\n",
        "    #Set Initial Image Path\n",
        "    iniName = aida.name(_ini_ls_str)\n",
        "    #Set Batch option [option as list in config.ini]\n",
        "    option_ls = TRANSweight_ls\n",
        "    str(option_ls)\n",
        "    #Run loop using images in '/content/in/styles/*' with '/content/in/ini/initialImage.png'\n",
        "    for style, option in zip(_style_ls,option_ls):\n",
        "        #Set output file path and name\n",
        "        styleName = aida.name(option)\n",
        "        optionName = aida.name(style)\n",
        "        ##Make the output folder for the runs\n",
        "        aida.mk(f'{_outPath}/{rendererName}/images/{_project}/run_{_exp}/{iniName}/{optionName}/{styleName}/')\n",
        "        outImg = f'{_outPath}/{rendererName}/images/{_project}/run_{_exp}/{iniName}/{optionName}/{styleName}/{iniName}-x-{styleName}---{optionName}'\n",
        "        #Run the Renderer\n",
        "        !style_transfer $_ini_ls_str $style --save-every $TRANSsave --iterations $TRANSrun --tv-weight $TRANStv_weight --content-weight $TRANSweight -o $outImg -s $TRANSsize\n",
        "        #Sync `/content/out' '/mnt/drive/MyDrive/aida/out\n",
        "        aida.syncDir(_outPath,_outPathDrive)\n",
        "else:\n",
        "    aida.txt(f'{rendererName} Transfer Not Selected in', \"conif.ini\")     "
      ],
      "metadata": {
        "cellView": "form",
        "id": "nDApl1EG3nW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // Neural Transfer - Archive\n",
        "if TRANed=='TRUE':\n",
        "  rendererName = \"TRANS\" #[CHANGE FOR EACH RENDERER]\n",
        "  from pathlib import Path\n",
        "  finalIn = Path(\"/content/out/images/{rendererName}/\")\n",
        "  finalOut = f'/content/out/final/{rendererName}/{_project}/run_{_exp}'\n",
        "  aida.mk(finalOut)\n",
        "  pat = f'*{_run}*.png'\n",
        "  #COPY - Final iterations '../final/project/run/'\n",
        "  for final in finalIn.rglob(pat):\n",
        "    !cp $final $finalOut\n",
        "  #SYNC\n",
        "  aida.syncDir(_outPath,_outPathDrive)\n",
        "  #CONTACT - Final Run\n",
        "  _finalLs = aida.ls(finalOut)\n",
        "  _finalLs_str = aida.ls2str(_finalLs)\n",
        "  out = f'/content/out/contacts/{rendererName}/{_project}/run_{_exp}/contact.jpg'\n",
        "  aida.mk(f'/content/out/contacts/{rendererName}/{_project}/run_{_exp}/')\n",
        "  aida.mk(f'/content/out/gifs/{rendererName}/{_project}/run_{_exp}/')\n",
        "  #GIF - Final Renders\n",
        "  gifName = f'{rendererName}/{_project}/run_{_exp}/final'\n",
        "  !montage -geometry 216x+0 -background grey34 $_finalLs_str $out\n",
        "  _gif(_finalLs_str,gifName,\"100\",\"70%\")\n",
        "  #SYNC\n",
        "  aida.syncDir(_outPath,_outPathDrive)\n",
        "  #GIF - all run iterations\n",
        "  rootdir = '/content/out/images/{rendererName}/'\n",
        "  frames_ls = []\n",
        "  for subdir, dirs, files in os.walk(rootdir):\n",
        "      for file in files:\n",
        "          frames_ls.append(os.path.join(subdir, file))\n",
        "  frames = aida.ls2str(frames_ls)\n",
        "  aida.mk('/content/out/gifs/{rendererName}/frames')\n",
        "  _gif(frames,\"{rendererName}/frames/frames\",\"30\",\"70%\")\n",
        "  #SYNC\n",
        "  from datetime import datetime\n",
        "  now = datetime.now()\n",
        "  timeSlug = now.strftime(\"%H-%M-%S\")\n",
        "  aida.zip( f'{_archivePath}/{rendererName}/{_project}-run_{_exp}_{timeSlug}.zip','/content/out')\n",
        "  aida.syncDir(_outPath,_outPathDrive)\n",
        "else:\n",
        "  aida.txt(f'{rendererName} Transfer Not Selected in', \"conif.ini\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UrScA3J83o8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // RENDER - StyleTransfer [pytorch]\n",
        "if TRANed=='TRUE':\n",
        "  \n",
        "  # aida.syncDir(_outPath,_outPathDrive)\n",
        "else:\n",
        "    aida.txt(\"Style Transfer Not Selected in\", \"conif.ini\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q582YatFWuHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // RENDER - FILM\n",
        "if FILMed=='TRUE':\n",
        "  print('hello')\n",
        "  aida.syncDir(_outPath,_outPathDrive)\n",
        "else:\n",
        "  aida.txt(\"FILM Not Selected in\", \"conif.ini\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tCiDPbowXqNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // RENDER - SuperRez\n",
        "if SUPERed=='TRUE':\n",
        "  print('hello')\n",
        "  aida.syncDir(_outPath,_outPathDrive)\n",
        "else:\n",
        "  aida.txt(\"SuperRez Not Selected in\", \"conif.ini\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m8-ULAg0XqFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###// **AiDa** Archive"
      ],
      "metadata": {
        "id": "qmp4nvwd64wj"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Aida_Common.ipynb",
      "provenance": [],
      "background_execution": "on",
      "authorship_tag": "ABX9TyP5acT1xBYM2i+Yh5tQCs7m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}