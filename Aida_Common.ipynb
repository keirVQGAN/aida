{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keirVQGAN/aida/blob/main/Aida_Common.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####// **AiDa** Setup"
      ],
      "metadata": {
        "id": "irQ0Hzw056yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown  <------------ //Aida Common Setup\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from distutils.dir_util import copy_tree\n",
        "import json\n",
        "from IPython import display\n",
        "from IPython.display import Image\n",
        "\n",
        "def _gif(lists,out,delay,scale):\n",
        "  gifOut = f'/content/out/gifs/{out}.gif'\n",
        "  !convert -delay $delay -resize $scale -loop 0 $lists $gifOut\n",
        "\n",
        "def gifShow(Path):\n",
        "  with open(Path,'rb') as f:\n",
        "      a = display.Image(data=f.read(), format='png')\n",
        "      return a\n",
        "\n",
        "#VARIABLES\n",
        "localPath = '/content'\n",
        "tmpPath = f'{localPath}/tmp'\n",
        "#GITHUB - Aida.git\n",
        "gitted = os.path.isdir(tmpPath)\n",
        "if gitted==0:\n",
        "  os.makedirs(tmpPath, exist_ok=\"True\")\n",
        "  !git clone https://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@github.com/keirVQGAN/aida /content/tmp\n",
        "copied = os.path.isfile(f'{localPath}/aida.py')\n",
        "if copied==0:\n",
        "  copy_tree(tmpPath, localPath)\n",
        "#INSTALL - Requirements\n",
        "!pip install -r requirements.txt &> /dev/null\n",
        "import aida\n",
        "#CLONE - IN\n",
        "clonned = os.path.isdir('/content/in')\n",
        "if clonned==0:\n",
        "  aida.clone()\n",
        "#Import [DEFAULT] Paths\n",
        "config_file = '/content/config.ini'\n",
        "import configparser\n",
        "config = configparser.ConfigParser()\n",
        "config.read(config_file)\n",
        "_project_ls = json.loads(config.get(\"DEFAULT\",\"PROJECT\"))\n",
        "_exp_ls = json.loads(config.get(\"DEFAULT\",\"EXPERIMENT\"))\n",
        "_drivePath_ls = json.loads(config.get(\"DEFAULT\",\"DRIVE_PATH\"))\n",
        "_localPath_ls = json.loads(config.get(\"DEFAULT\",\"LOCAL_PATH\"))\n",
        "_modelsPath_ls = json.loads(config.get(\"DEFAULT\",\"MODELS_PATH\"))\n",
        "_modelsPathDrive_ls = json.loads(config.get(\"DEFAULT\",\"MODELS_PATH_DRIVE\"))\n",
        "_inPath_ls = json.loads(config.get(\"DEFAULT\",\"IN_PATH\"))\n",
        "_inPathDrive_ls = json.loads(config.get(\"DEFAULT\",\"IN_PATH_DRIVE\"))\n",
        "_outPath_ls = json.loads(config.get(\"DEFAULT\",\"OUT_PATH\"))\n",
        "_outPathDrive_ls = json.loads(config.get(\"DEFAULT\",\"OUT_PATH_DRIVE\"))\n",
        "_contactPath_ls = json.loads(config.get(\"DEFAULT\",\"CONTACT_PATH\"))\n",
        "_archivePath_ls = json.loads(config.get(\"DEFAULT\",\"ARCHIVE_PATH\"))\n",
        "_iniPath_ls = json.loads(config.get(\"IMAGES\",\"INI_PATH\"))\n",
        "_stylesPath_ls = json.loads(config.get(\"IMAGES\",\"STYLES_PATH\"))\n",
        "_maskPath_ls = json.loads(config.get(\"IMAGES\",\"MASKS_PATH\"))\n",
        "\n",
        "NEURALed_ls = json.loads(config.get(\"DEFAULT\", \"NEURAL\"))\n",
        "TRANed_ls = json.loads(config.get(\"DEFAULT\", \"TRANS\"))\n",
        "FILMed_ls = json.loads(config.get(\"DEFAULT\", \"FILM\"))\n",
        "SUPERed_ls = json.loads(config.get(\"DEFAULT\", \"SUPER\"))\n",
        "TXT2IMGed_ls = json.loads(config.get(\"DEFAULT\", \"TXT2IMG\"))\n",
        "\n",
        "_project = aida.ls2str(_project_ls)\n",
        "_exp = aida.ls2str(_exp_ls)\n",
        "_drivePath = aida.ls2str(_drivePath_ls)\n",
        "_localPath = aida.ls2str(_localPath_ls)\n",
        "_modelsPath = aida.ls2str(_modelsPath_ls)\n",
        "_modelsPathDrive = aida.ls2str(_modelsPathDrive_ls)\n",
        "_inPath = aida.ls2str(_inPath_ls)\n",
        "_inPathDrive = aida.ls2str(_inPathDrive_ls)\n",
        "_outPath = aida.ls2str(_outPath_ls)\n",
        "_outPathDrive = aida.ls2str(_outPathDrive_ls)\n",
        "_contactPath = aida.ls2str(_contactPath_ls)\n",
        "_archivePath = aida.ls2str(_archivePath_ls)\n",
        "_iniPath = aida.ls2str(_iniPath_ls)\n",
        "_stylesPath = aida.ls2str(_stylesPath_ls)\n",
        "_maskPath = aida.ls2str(_maskPath_ls)\n",
        "\n",
        "NEURALed = aida.ls2str(NEURALed_ls)\n",
        "TRANed = aida.ls2str(TRANed_ls)\n",
        "FILMed = aida.ls2str(FILMed_ls)\n",
        "SUPERed = aida.ls2str(SUPERed_ls)\n",
        "TXT2IMGed = aida.ls2str(TXT2IMGed_ls)\n",
        "\n",
        "#Get images lists\n",
        "_ini_ls = aida.ls(_iniPath)\n",
        "_ini_ls_str = aida.ls2str(_ini_ls)\n",
        "_style_ls = aida.ls(_stylesPath)\n",
        "_style_ls_str = aida.ls2str(_style_ls)\n",
        "_mask_ls = aida.ls(_maskPath)\n",
        "_mask_ls_str = aida.ls2str(_mask_ls)\n",
        "\n",
        "!apt install imagemagick &> /dev/null\n",
        "aida.mk(f'{_outPath}/gifs')\n",
        "\n",
        "style_gifed = os.path.isdir('/content/out/gifs/styles.gif')\n",
        "if style_gifed ==0:\n",
        "  aida.mk('/content/out/gifs/styles/')\n",
        "  _gif(_style_ls_str,\"/styles/styles\",\"100\",\"17%\")\n",
        "\n",
        "#Clean Up\n",
        "tmpd = os.path.isdir('/content/tmp')\n",
        "sampled = os.path.isdir('/content/sample_data')\n",
        "if tmpd==1:\n",
        "  aida.rm('/content/tmp')\n",
        "if sampled==1:\n",
        "  aida.rm('/content/sample_data') \n",
        "\n",
        "#Console\n",
        "installed = ['AiDa', 'requirements']\n",
        "cloned = ['github/keirVQGAN/aida','/mnt/drive/aida/in']\n",
        "#CONFIG [DEFAULT] LISTS\n",
        "paramConfigDefault = [\"PROJECT\",\"DRIVE_PATH\",\"LOCAL_PATH\",\"MODELS_PATH\",\"MODELS_PATH_DRIVE\",\"IN_PATH\",\"IN_PATH_DRIVE\",\"OUT_PATH\",\"OUT_PATH_DRIVE\",\"CONTACT_PATH\",\"ARCHIVE_PATH\"]\n",
        "valueConfigDefault = [_project,_drivePath,_localPath,_modelsPath,_modelsPathDrive,_inPath,_inPathDrive,_outPath,_outPathDrive,_contactPath,_archivePath]\n",
        "paramConfigImages = [\"INI_PATH\",\"STYLES_PATH\",\"MASKS_PATH\"]\n",
        "valueConfigImages = [_iniPath,_stylesPath,_maskPath]\n",
        "paramConfigRenderers = \"NEURAL\",\"TRANS\",\"FILM\",\"SUPER\",\"TXT2IMG\"\n",
        "valueConfigRenderers = NEURALed,TRANed,FILMed,SUPERed,TXT2IMGed\n",
        "\n",
        "aida.txtH('AiDa v0.1 // Setup')\n",
        "for q in installed:\n",
        "  aida.txtC('Installed',q)\n",
        "for w in cloned:\n",
        "  aida.txtY('Cloned', w)\n",
        "aida.txtM('Imported', '[DEFAULT] config')\n",
        "aida.txtH('Renderers Selected:')\n",
        "for y,x in zip(paramConfigRenderers,valueConfigRenderers):\n",
        "  x = config.get(\"NEURAL\", y)\n",
        "  aida.txt(y,x)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FKeJ-GqX4wEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYgCr21UEfoA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "if NEURALed==1:\n",
        "  #@markdown <----------- **AiDa** // INSTALL - NeuralStyle Transfer\n",
        "  #Import [Neural] Parameters\n",
        "  from IPython.core.interactiveshell import InteractiveShell\n",
        "  InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "  config.read(config_file)\n",
        "  _img_size_ls = json.loads(config.get(\"NEURAL\", \"IMG_SIZE\"))\n",
        "  _run_ls = json.loads(config.get(\"NEURAL\", \"RUN\"))\n",
        "  _style_weight_ls = json.loads(config.get(\"NEURAL\", \"STYLE_WEIGHT\"))\n",
        "  _min_improvement_ls = json.loads(config.get(\"NEURAL\", \"MIN_IMPROVEMENT\"))\n",
        "  _content_weight_ls = json.loads(config.get(\"NEURAL\", \"CONTENT_WEIGHT\"))\n",
        "  _content_loss_type_ls = json.loads(config.get(\"NEURAL\", \"CONTENT_LOSS_TYPE\"))\n",
        "  _pool_type_ls = json.loads(config.get(\"NEURAL\", \"POOL_TYPE\"))\n",
        "  _tv_weight_ls = json.loads(config.get(\"NEURAL\", \"TV_WEIGHT\"))\n",
        "  _model_ls = json.loads(config.get(\"NEURAL\", \"MODEL\"))\n",
        "\n",
        "  _img_size =  aida.ls2str(_img_size_ls)\n",
        "  _run =  aida.ls2str(_run_ls)\n",
        "  _style_weight =  aida.ls2str(_style_weight_ls)\n",
        "  _min_improvement =  aida.ls2str(_min_improvement_ls)\n",
        "  _content_weight =  aida.ls2str(_content_weight_ls)\n",
        "  _content_loss_type =  aida.ls2str(_content_loss_type_ls)\n",
        "  _pool_type =  aida.ls2str(_pool_type_ls)\n",
        "  _tv_weight =  aida.ls2str(_tv_weight_ls)\n",
        "  _model = aida.ls2str(_model_ls)\n",
        "\n",
        "  #Install Requirements\n",
        "  from IPython.display import Image\n",
        "  %tensorflow_version 1.x\n",
        "\n",
        "  !pip install -q 'scipy<=1.2.1' &> /dev/null\n",
        "  gittedNeu = os.path.isdir('/content/Neural-Style-Transfer')\n",
        "  if gittedNeu==0:\n",
        "    !git clone https://github.com/titu1994/Neural-Style-Transfer.git &> /dev/null\n",
        "  dir_path = \"Neural-Style-Transfer\"\n",
        "  NETWORK = 'INetwork' + '.py'\n",
        "\n",
        "  #Console\n",
        "  paramConfig = [\"RUN\",\"IMG_SIZE\",\"CONTENT_WEIGHT\",\"STYLE_WEIGHT\",\"MIN_IMPROVEMENT\",\"CONTENT_LOSS_TYPE\",\"TV_WEIGHT\",\"POOL_TYPE\",\"MODEL\"]\n",
        "  valueConfig = [_run,_img_size,_content_weight,_style_weight,_min_improvement,_content_loss_type,_tv_weight,_pool_type,_model]\n",
        "  aida.txtH('AiDa v0.1 // NeuralTransfer')\n",
        "  aida.txtC('Installed','requirements')\n",
        "  print()\n",
        "  aida.txtM(_project,f'run_{_exp}')\n",
        "  for y,x in zip(paramConfig,valueConfig):\n",
        "    x = config.get(\"NEURAL\", y)\n",
        "    aida.txt(y,x)\n",
        "  print()\n",
        "  gifShow('/content/out/gifs/styles/styles.gif')\n",
        "  Image(_ini_ls_str, width=218)\n",
        "else:\n",
        "  aida.txtH('Neural Transfer Not Selected')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <----------- **AiDa** // INSTALL - StyleTransfer [pytorch]\n",
        "#Import [Neural] Parameters\n",
        "config.read(config_file)\n",
        "_img_size_ls = json.loads(config.get(\"NEURAL\", \"IMG_SIZE\"))\n",
        "_run_ls = json.loads(config.get(\"NEURAL\", \"RUN\"))\n",
        "_style_weight_ls = json.loads(config.get(\"NEURAL\", \"STYLE_WEIGHT\"))\n",
        "_min_improvement_ls = json.loads(config.get(\"NEURAL\", \"MIN_IMPROVEMENT\"))\n",
        "_content_weight_ls = json.loads(config.get(\"NEURAL\", \"CONTENT_WEIGHT\"))\n",
        "_content_loss_type_ls = json.loads(config.get(\"NEURAL\", \"CONTENT_LOSS_TYPE\"))\n",
        "_pool_type_ls = json.loads(config.get(\"NEURAL\", \"POOL_TYPE\"))\n",
        "_tv_weight_ls = json.loads(config.get(\"NEURAL\", \"TV_WEIGHT\"))\n",
        "_model_ls = json.loads(config.get(\"NEURAL\", \"MODEL\"))\n",
        "\n",
        "_img_size =  aida.ls2str(_img_size_ls)\n",
        "_run =  aida.ls2str(_run_ls)\n",
        "_style_weight =  aida.ls2str(_style_weight_ls)\n",
        "_min_improvement =  aida.ls2str(_min_improvement_ls)\n",
        "_content_weight =  aida.ls2str(_content_weight_ls)\n",
        "_content_loss_type =  aida.ls2str(_content_loss_type_ls)\n",
        "_pool_type =  aida.ls2str(_pool_type_ls)\n",
        "_tv_weight =  aida.ls2str(_tv_weight_ls)\n",
        "_model = aida.ls2str(_model_ls)\n",
        "\n",
        "gittedTrans = os.path.isdir('/content/style-transfer-pytorch')\n",
        "if gittedTrans==0:\n",
        "  !git clone https://github.com/crowsonkb/style-transfer-pytorch    &> /dev/null\n",
        "  !pip install -e ./style-transfer-pytorch &> /dev/null"
      ],
      "metadata": {
        "cellView": "code",
        "id": "CjeywiACkOZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####// **AiDa** Render"
      ],
      "metadata": {
        "id": "NFob7Xny6DzA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDgAJ7MHxubZ"
      },
      "outputs": [],
      "source": [
        "#@markdown <----------- **AiDa** // RENDER BATCH - NeuralStyle Transfer\n",
        "import time\n",
        "for style,tv in zip(_style_ls,_content_weight_ls):\n",
        "  iniName = aida.name(_ini_ls_str)\n",
        "  styleName = aida.name(style)\n",
        "  outImg = f'{_outPath}/images/{_project}/run_{_exp}/{iniName}/{tv}/{styleName}/{iniName}-x-{styleName}---{tv}'\n",
        "  str(tv)\n",
        "  aida.mk(f'{_outPath}/images/{_project}/run_{_exp}/{iniName}/{tv}/{styleName}/')\n",
        "  !python /content/Neural-Style-Transfer/INetwork.py $_ini_ls_str $style $outImg --image_size $_img_size --num_iter $_run --style_weight $_style_weight --content_weight $tv\n",
        "  aida.syncDir(_outPath,_outPathDrive)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####// **AiDa** Archive"
      ],
      "metadata": {
        "id": "qmp4nvwd64wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "#@markdown <----------- **AiDa** // Post and Archive Run\n",
        "finalIn = Path(\"/content/out/images\")\n",
        "finalOut = f'/content/out/final/{_project}/run_{_exp}'\n",
        "aida.mk(finalOut)\n",
        "pat = f'*{_run}*.png'\n",
        "#COPY - Final iterations '../final/project/run/'\n",
        "for final in finalIn.rglob(pat):\n",
        "  !cp $final $finalOut\n",
        "#SYNC\n",
        "aida.syncDir(_outPath,_outPathDrive)\n",
        "#CONTACT - Final Run\n",
        "_finalLs = aida.ls(finalOut)\n",
        "_finalLs_str = aida.ls2str(_finalLs)\n",
        "out = f'/content/out/contacts/{_project}/run_{_exp}/contact.jpg'\n",
        "aida.mk(f'/content/out/contacts/{_project}/run_{_exp}/')\n",
        "aida.mk(f'/content/out/gifs/{_project}/run_{_exp}/')\n",
        "#GIF - Final Renders\n",
        "gifName = f'{_project}/run_{_exp}/final'\n",
        "!montage -geometry 216x+0 -background grey34 $_finalLs_str $out\n",
        "_gif(_finalLs_str,gifName,\"100\",\"70%\")\n",
        "#SYNC\n",
        "aida.syncDir(_outPath,_outPathDrive)\n",
        "#GIF - all run iterations\n",
        "rootdir = '/content/out/images'\n",
        "frames_ls = []\n",
        "for subdir, dirs, files in os.walk(rootdir):\n",
        "    for file in files:\n",
        "        frames_ls.append(os.path.join(subdir, file))\n",
        "frames = aida.ls2str(frames_ls)\n",
        "aida.mk('/content/out/gifs/frames')\n",
        "_gif(frames,\"/frames/frames\",\"30\",\"70%\")\n",
        "#SYNC\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "timeSlug = now.strftime(\"%H-%M-%S\")\n",
        "aida.zip( f'{_archivePath}/{_project}-run_{_exp}_{timeSlug}.zip','/content/out')\n",
        "aida.syncDir(_outPath,_outPathDrive)"
      ],
      "metadata": {
        "id": "J4D3VIWJEZdw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "irQ0Hzw056yV",
        "qmp4nvwd64wj"
      ],
      "name": "Aida_Common.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMTQKlv7d6z/UQDYEviBNWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}