# Use VISSL config system as a model of hydra/omegaconf best practices
#  - https://github.com/facebookresearch/vissl/blob/main/vissl/config/defaults.yaml
#  - https://vissl.readthedocs.io/en/latest/hydra_config.html

defaults:
  - _self_
  - conf: _empty

#############
## Prompts ##
#############

scenes: ???
scene_prefix: ''
scene_suffix: ''

direct_image_prompts: ''
init_image: ''
direct_init_weight: ''
semantic_init_weight: ''

##################################

# image_model:
#   - Unlimited Palette
#   - Limimted Palette
#   - VQGAN
image_model: Unlimited Palette

# vqgan_model:
#   - sflickr
#   - imagenet
#   - coco
#   - wikiart
#   - openimages
vqgan_model: sflckr

# animation_mode:
#    - off
#    - Video Source
#    - 2D
#    - 3D
animation_mode: off

##################################

width: 180
height: 112

steps_per_scene: 100
steps_per_frame: 50
interpolation_steps: 0

learning_rate: null
reset_lr_each_frame: true
seed: ${now:%f} # microsecond component of timestamp. Basically random.
cutouts: 40
cut_pow: 2
cutout_border: 0.25

# border_mode:
#    - clamp
#    - mirror
#    - wrap
#    - black
#    - smear
border_mode: clamp

##################################

##########
# Camera #
##########

field_of_view: 60
near_plane: 1
far_plane: 10000

######################
### Induced Motion ###
######################
input_audio: ""
input_audio_offset: 0
input_audio_filters: []
# - variable_name: fLo
#   f_center: 60
#   f_width: 30
#   order: 5

pre_animation_steps: 100
lock_camera: true

#  _2d and _3d only apply to those animation modes

translate_x: '0'
translate_y: '0'
translate_z_3d: '0'
rotate_3d: '[1, 0, 0, 0]'
rotate_2d: '0'
zoom_x_2d: '0'
zoom_y_2d: '0'


# sampling_mode:
#    - nearest
#    - bilinear
#    - bicubic
sampling_mode: bicubic

# infill_mode:
#    - mirror
#    - wrap
#    - black
#    - smear
infill_mode: wrap

##################################

#######################
### Limited Palette ###
#######################

pixel_size: 4
smoothing_weight: 0.02
random_initial_palette: false
palette_size: 6
palettes: 9
gamma: 1
hdr_weight: 0.01
palette_normalization_weight: 0.2
show_palette: false
target_palette: ''
lock_palette: false

##############
### ffmpeg ###
##############

frames_per_second: 12

direct_stabilization_weight: ''
semantic_stabilization_weight: ''
depth_stabilization_weight: ''
edge_stabilization_weight: ''
flow_stabilization_weight: ''

#####################################
### animation_mode = Video Source ###
#####################################

video_path: ''
frame_stride: 1
reencode_each_frame: true
flow_long_term_samples: 1

############
### CLIP ###
############

ViTB32: true
ViTB16: false
ViTL14: false
ViTL14_336px: false
RN50: false
RN101: false
RN50x4: false
RN50x16: false
RN50x64: false

###############
### Outputs ###
###############

file_namespace: default
allow_overwrite: false
display_every: 50
clear_every: 0
display_scale: 1
save_every: 50

backups: 0
show_graphs: false
approximate_vram_usage: false
use_tensorboard: false

#####################################

#################
### Model I/O ###
#################

# This is where pytti will expect to find model weights.
# Each model will be assigned a separate subdirectory within this folder
# If the expected model artifacts are not present, pytti will attempt to download them.
models_parent_dir: ${user_cache:}

######################################

##########################
### Performance tuning ###
##########################

gradient_accumulation_steps: 1
